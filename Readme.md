# AI-assisted materials synthesizability prediction from crystallographic structure using structure-aware transformers

ğŸ§© **Overview**  
This repository contains the official codebase for **structure-based materials synthesizability prediction** using transformer architectures operating on the **Fourier-Transformed Crystal Properties (FTCP)** representation. The goal is to learn synthesizability patterns directly from crystallographic structure (rather than relying only on thermodynamic stability heuristics), enabling improved screening of hypothetical inorganic crystals and more reliable prioritization for experimental validation.

ğŸ§‘â€ğŸ”¬ **Authors**
- **Danial Ebrahimzadeh** (University of Oklahoma)
- **Sarah Sharif** (University of Oklahoma)
- **Nisha Geng** (University of Oklahoma)
- **Yaser Mike Banad** (University of Oklahoma) â€” *Corresponding Author* (bana@ou.edu)

ğŸ“„ **Abstract**
Computational methods can now predict millions of hypothetical crystalline materials with desirable properties, yet only a tiny fraction can be experimentally synthesized. Traditional screening relies on thermodynamic stability calculations, which achieve modest accuracy ( 60%) in distinguishing synthesizable from non-synthesizable phases. Here, we demonstrate that transformer neural networks trained on crystallographic structure data substantially outperform energy-based approaches for synthesizability prediction. We compare three transformer architectures processing Fourier-transformed crystal properties (FTCP) representation: a domain-agnostic design, a hierarchical spatial model, and a structure-aware architecture that explicitly decomposes crystallographic components. An ensemble combining the two best-performing models achieves 90.88% accuracy and 96.47% ROC-AUC, providing twofold higher precision and fivefold fewer false positives than DFT stability criteria. Case study of twelve lithium niobate polymorphs shows that our weight-optimized ensemble prediction successfully discriminates among structurally distinct variants with near-identical thermodynamics, demonstrating the benefit of combining complementary architectural features. These results establish that learning from experimental synthesis outcomes captures the complex interplay of thermodynamics, kinetics, and synthesis pathways governing materials realizability.

ğŸ§¾ **License**
This repository is released under the **MIT License**.

---

ğŸ“¦ **Dataset (Required)**
> **Important:** The primary dataset file is **>2 GB** and is **not included** in the GitHub repository.

âœ… **Download the FTCP dataset and place it here:** `data/ftcp_data.h5`  
- **Hugging Face (click to download):** [ftcp_data.h5](https://huggingface.co/datasets/danial199472/synthesizability-transformers/resolve/main/ftcp_data.h5)

If you already have the file locally (example Windows location):
- `C:\Users\dania\Research\SyntheFormer\Nature_MC\files\data\ftcp_data.h5`  
Copy it into this repository as:
- `./data/ftcp_data.h5`

---

ğŸ—‚ï¸ **Repository structure**
```text
.
â”œâ”€ data/
â”‚  â”œâ”€ ftcp_data.h5                      # (download separately; >2GB)
â”‚  â””â”€ mp_structures_with_synthesizability1.xlsx
â”œâ”€ ft-t/
â”‚  â”œâ”€ dataset_balanced_fixed.py
â”‚  â”œâ”€ data_split_info.json
â”‚  â”œâ”€ ft_transformer_model.py
â”‚  â”œâ”€ save_data_split.py
â”‚  â””â”€ train_ft.py
â”œâ”€ SwinT/
â”‚  â”œâ”€ dataset_balanced_fixed.py
â”‚  â”œâ”€ requirements.txt
â”‚  â”œâ”€ save_data_split.py
â”‚  â”œâ”€ swin_transformer_model.py
â”‚  â”œâ”€ train_swin.py
â”‚  â””â”€ results/
â”‚     â””â”€ best_model.pth
â”œâ”€ SAT/
â”‚  â”œâ”€ train_model.py
â”‚  â”œâ”€ configs/
â”‚  â”‚  â””â”€ structure_transformer.yaml
â”‚  â”œâ”€ src/
â”‚  â”‚  â”œâ”€ data/
â”‚  â”‚  â”‚  â””â”€ dataset.py
â”‚  â”‚  â”œâ”€ models/
â”‚  â”‚  â”‚  â””â”€ structure_transformer.py
â”‚  â”‚  â””â”€ training/
â”‚  â”‚     â””â”€ train.py
â”‚  â””â”€ results/
â”‚     â””â”€ best_model.pt
â”œâ”€ Ensemble/
â”‚  â”œâ”€ ensemble_model.py
â”‚  â””â”€ optimize_weights.py
â”œâ”€ requirements.txt
â””â”€ REPO-TREE.txt

````

---
âš™ï¸ Installation
Create a virtual environment and install dependencies:
python -m venv .venv
# Windows:
#   .venv\Scripts\activate
# macOS/Linux:
#   source .venv/bin/activate

pip install -r requirements.txt


ğŸ§  Models included

FT-T (Feature Tokenizer Transformer): ft-t/

SwinT (Shifted-window hierarchical attention): SwinT/

SAT (Structure-Aware Transformer with component-wise encoding): SAT/

Weighted Ensemble (SAT + SwinT): Ensemble/


ğŸš€ Quickstart

Download the dataset and place it at: data/ftcp_data.h5

Install requirements

Train or run a model:

FT-T: ft-t/train_ft.py

SwinT: SwinT/train_swin.py

SAT: SAT/train_model.py

Ensemble: Ensemble/ensemble_model.py

Note: Some scripts may assume specific local paths or configurations. If needed, adjust dataset paths at the top of each script/config.

ğŸ” Ensemble weights
The ensemble combines SAT and SwinT probabilities via a weighted average. Weight-search utilities are provided in:

Ensemble/optimize_weights.py

ğŸ“¬ Contact

Corresponding author: Yaser Mike Banad â€” bana@ou.edu

First author: Danial Ebrahimzadeh â€” danial.ebrahimzadeh@ou.edu